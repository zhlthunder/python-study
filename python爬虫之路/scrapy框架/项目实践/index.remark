dangdang: 是当当网的商品爬虫实战；

taoyun_login: scrapy模拟登陆实战； 需要使用fiddler 抓包获取真正的URL地址；
进入项目目录下，执行scrapy crawl login 运行爬虫；
说明：我们可以使用scrapy代替人去登录一些网站，登录之后可以爬取深层页面。


baidunews:
百度新闻爬虫实战： 需求，抓取百度新闻首页中的所有新闻信息；
在百度新闻首页，除了热点新闻外，其它的新闻在源码中都找不到，那我们就必须通过抓包分析找到对应的js文件，并从js文件中获取所需的新闻；
另外，爬取新闻时，需要去重， 有两种方法：
1.如果写入数据库，可以采用数据库自带的去重功能，比如设置某个字段为uniq
2.过滤器，推荐使用布隆过滤器，我们需要在python中实现 布隆过滤器的功能；

创建步骤：
scrapy startproject baidunews
cd baidunews
scrapy genspider -t basic n1 baidu.com

抓包分析：
http://news.baidu.com/widget?id=LocalNews&ajax=json&t=1521728600256
http://news.baidu.com/widget?id=LocalNews&ajax=json&t=1521728600256
http://news.baidu.com/widget?id=civilnews&t=1521728978422
http://news.baidu.com/widget?id=InternationalNews&t=1521728978452
http://news.baidu.com/widget?id=EnterNews&t=1521728978474
http://news.baidu.com/widget?id=SportNews&t=1521728978502
http://news.baidu.com/widget?id=FinanceNews&t=1521728978526
http://news.baidu.com/widget?id=TechNews&t=1521728978580
http://news.baidu.com/widget?id=MilitaryNews&t=1521728980252
http://news.baidu.com/widget?id=InternetNews&t=1521728980292
http://news.baidu.com/widget?id=DiscoveryNews&t=1521728980306
http://news.baidu.com/widget?id=LadyNews&t=1521728980338
http://news.baidu.com/widget?id=HealthNews&t=1521728980360
http://news.baidu.com/widget?id=PicWall&t=1521728980422


downlaod_project:https://blog.csdn.net/u013398398/article/details/53676515


douban: 豆瓣网登录爬虫与验证码自动识别