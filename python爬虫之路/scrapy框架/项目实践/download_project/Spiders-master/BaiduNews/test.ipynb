{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import requests\n",
    "import hashlib\n",
    "import urllib2\n",
    "import urllib\n",
    "import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from urllib import quote\n",
    "import time\n",
    "\n",
    "def crawl(url):\n",
    "    user_agent = 'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36'\n",
    "    headers = {'User-Agent': user_agent}\n",
    "    request = urllib2.Request(url, headers=headers)\n",
    "    response = urllib2.urlopen(request) \n",
    "    html = response.read()\n",
    "    soup = BeautifulSoup(html, from_encoding='utf-8')\n",
    "    return soup\n",
    "\n",
    "def parse(soup):\n",
    "    results = soup.find('div', id='content_left').find_all('div', class_='result')\n",
    "    ans = []\n",
    "    for result in results:\n",
    "        # title: 新闻标题\n",
    "        # title_url: 新闻链接\n",
    "        # source_and_time: 作者/时间\n",
    "        # source: 作者\n",
    "        # time: 时间\n",
    "        # summary: 摘要\n",
    "        # simi_words: 相同新闻\n",
    "        # simi_words_url: 相同新闻查询的url\n",
    "        # simi_words_search: cont:....\n",
    "        title = result.find('h3', class_='c-title').find('a').get_text()\n",
    "        title_url = result.find('h3', class_='c-title').find('a')['href']\n",
    "        try:\n",
    "            abstract = result.find('div', class_='c-summary c-row ').get_text()\n",
    "        except:\n",
    "            abstract = result.find('div', class_='c-span18 c-span-last').get_text()\n",
    "        try:\n",
    "            source_and_time = result.find('p', class_='c-author').get_text()\n",
    "            source, time = source_and_time.split(u'\\xa0'u'\\xa0')\n",
    "        except:\n",
    "            source_and_time = \"\"\n",
    "            source = \"\"\n",
    "            time = \"\"\n",
    "        temp_abstract = abstract[len(source_and_time):]\n",
    "        summary = \"\"\n",
    "        for word in temp_abstract:\n",
    "            summary = summary + word\n",
    "            if summary[-3:] == '...':\n",
    "                break\n",
    "        temp_list = [title, title_url, source, time, summary]\n",
    "        temp = \" \"\n",
    "        try:\n",
    "            simi_words = result.find('a', class_='c-more_link').get_text()\n",
    "            simi_words_url = 'http://news.baidu.com' + result.find('a', class_='c-more_link')['href']\n",
    "            i = 0\n",
    "            while i != len(simi_words_url) - 1:\n",
    "                if simi_words_url[i] == '+':\n",
    "                    while simi_words_url[i] != '&':\n",
    "                        temp = temp + simi_words_url[i]\n",
    "                        i = i + 1\n",
    "                else:\n",
    "                    i = i + 1\n",
    "        except:\n",
    "            simi_words = \"\"\n",
    "            simi_words_url = \"\"\n",
    "            temp = \"\"\n",
    "        temp_list.append(simi_words)\n",
    "        temp_list.append(simi_words_url)\n",
    "        temp_list.append(temp)\n",
    "        ans.append(temp_list)\n",
    "\n",
    "#     if is_homepage == 1:\n",
    "#         page_list = []\n",
    "#         try:    \n",
    "#             pages = soup.find('p', id='page').find_all('a')\n",
    "#             for page in pages:\n",
    "#                 page_list.append('http://news.baidu.com' + page['href'])\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#         return page_list, ans\n",
    "#     else:\n",
    "    return ans\n",
    "\n",
    "# def search(query_word):\n",
    "#     word = urllib.quote(query_word)\n",
    "#     url  = 'http://news.baidu.com/ns?cl=2&tn=news&word=' + word\n",
    "#     soup = crawl(url)\n",
    "#     page_list, ans = parse(soup, 1)\n",
    "#     return page_list, ans\n",
    "\n",
    "def search(query_word):\n",
    "    word = urllib.quote(query_word)\n",
    "    url  = 'http://news.baidu.com/ns?cl=2&tn=news&word=' + word\n",
    "    return url\n",
    "\n",
    "def get_more(page_list):\n",
    "    ans = []\n",
    "    for page in page_list:\n",
    "        soup = crawl(page)\n",
    "        temp_ans = parse(soup, 0)\n",
    "        ans = ans + temp_ans\n",
    "\n",
    "    return ans\n",
    "\n",
    "def get_same(url):\n",
    "    soup = crawl(url)\n",
    "    ans = parse(soup, 0)\n",
    "    return ans\n",
    "\n",
    "def date_filter(begin_date, end_date, query_word):\n",
    "    date0 = datetime.datetime.strptime(begin_date, \"%Y-%m-%d\")\n",
    "    date1 = datetime.datetime.strptime(end_date + \" 23:59:59\", \"%Y-%m-%d %H:%M:%S\")\n",
    "    y0, m0, d0 = str(date0.year), str(date0.month), str(date0.day)\n",
    "    y1, m1, d1 = str(date1.year), str(date1.month), str(date1.day)\n",
    "    query_word = quote(query_word)\n",
    "    bt = str(int(time.mktime(date0.timetuple())))\n",
    "    et = str(int(time.mktime(date1.timetuple())))\n",
    "    url = 'http://news.baidu.com/ns?from=news&cl=2&bt='+ bt + '&y0='+ y0 +'&m0=' + m0 + '&d0=' + d0 + '&y1=' + y1 + '&m1=' + m1 + '&d1=' + d1 + '&et=' + et + '&q1=' + query_word + '&submit=%B0%D9%B6%C8%D2%BB%CF%C2&q3=&q4=&mt=0&lm=&s=2&begin_date=' + begin_date + '&end_date=' + end_date + '&tn=newsdy&ct1=1&ct=1'\n",
    "    return url\n",
    "\n",
    "def page_filter(url, page=0):# append url with pn and rn params\n",
    "    # rn are set to be 20\n",
    "    if page is None:\n",
    "        page = 0\n",
    "    rn = 20\n",
    "    pn = page * rn\n",
    "    rn = str(rn)\n",
    "    pn = str(pn)\n",
    "    url = url + '&pn=' + pn\n",
    "    url = url + '&rn=' + rn\n",
    "    return url\n",
    "\n",
    "def search_with_page(query_word, page=0):\n",
    "    url = search(query_word)\n",
    "    url = page_filter(url, page)\n",
    "    return url\n",
    "\n",
    "def date_filter_with_page(begin_date, end_date, query_word, page=0):\n",
    "    url = date_filter(begin_date, end_date, query_word)\n",
    "    url = page_filter(url, page)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plist, ans = search('军民') #测试搜索词语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'\\u6d77\\u519b\\u4e0e\\u6d77\\u6d0b\\u5c40\\u7b7e\\u7f72\\u5408\\u4f5c\\u534f\\u8bae \\u63a8\\u52a8\\u519b\\u6c11\\u878d\\u5408',\n",
       " 'http://finance.sina.com.cn/roll/2017-04-21/doc-ifyepsra4982970.shtml',\n",
       " u'\\u65b0\\u6d6a\\u8d22\\u7ecf',\n",
       " u'26\\u5206\\u949f\\u524d',\n",
       " u'\\u4e2d\\u56fd\\u8bc1\\u5238\\u7f51\\u8baf\\u6d77\\u519b\\u4e0e\\u56fd\\u5bb6\\u6d77\\u6d0b\\u5c4021\\u65e5\\u5728\\u4eac\\u7b7e\\u7f72\\u519b\\u6c11\\u878d\\u5408\\u521b\\u65b0\\u53d1\\u5c55\\u6218\\u7565\\u5408\\u4f5c\\u6846\\u67b6\\u534f\\u8bae,\\u53cc\\u65b9\\u5546\\u5b9a\\u5728\\u6d77\\u6d0b\\u6218\\u7565\\u89c4\\u5212\\u3001\\u653f\\u7b56\\u6cd5\\u89c4\\u3001\\u7efc\\u5408\\u4fdd\\u969c\\u3001\\u7efc\\u5408\\u7ba1\\u7406\\u3001\\u6d77\\u4e0a\\u7ef4\\u6743\\u6267\\u6cd5\\u3001\\u4eba\\u624d\\u57f9\\u517b\\u4e0e\\u4ea4\\u6d41...',\n",
       " u'10\\u6761\\u76f8\\u540c\\u65b0\\u95fb',\n",
       " 'http://news.baidu.com/ns?word=%E5%86%9B%E6%B0%91+cont:2174988303&same=10&cl=1&tn=news&rn=30&fm=sd',\n",
       " ' +cont:2174988303']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 全市军民融合发展推进会在上杭召开\n",
      "1: http://www.ctw.cn/article/article_127512.html\n",
      "2: 长汀网\n",
      "3: 1小时前\n",
      "4: 昨日下午,全市军民融合发展推进会在上杭召开,回顾总结去年全市军民融合发展工作,传达贯彻市军民融合发展领导小组第一次会议精神,研究部署安排下一步工作。副市长谢海波...\n",
      "5: \n",
      "6: \n",
      "7: \n"
     ]
    }
   ],
   "source": [
    "# 测试相同新闻\n",
    "cnt = 0\n",
    "for elem in ans[3]:\n",
    "    print str(cnt) + ': ' + elem\n",
    "    cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://news.baidu.com/ns?word=%E5%86%9B%E6%B0%91+cont:2174988303&same=10&cl=1&tn=news&rn=30&fm=sd\n",
      " +cont:2174988303\n"
     ]
    }
   ],
   "source": [
    "print ans[0][6]\n",
    "temp = \" \"\n",
    "i = 0\n",
    "while i != len(ans[0][6]) - 1:\n",
    "    if ans[0][6][i] == '+':\n",
    "        while ans[0][6][i] != '&':\n",
    "            temp = temp + ans[0][6][i]\n",
    "            i = i + 1\n",
    "    else:\n",
    "        i = i + 1\n",
    "print temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n"
     ]
    }
   ],
   "source": [
    "all_other_news = get_more(plist[1:])# 测试 more\n",
    "print len(all_other_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2014, 12, 31, 23, 59, 59)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "a = datetime.datetime.strptime(\"2014-12-31\" + \" 23:59:59\", \"%Y-%m-%d %H:%M:%S\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from urllib import quote\n",
    "def date_filter(begin_date, end_date, query_word):\n",
    "    date0 = datetime.datetime.strptime(begin_date, \"%Y-%m-%d\")\n",
    "    date1 = datetime.datetime.strptime(end_date + \" 23:59:59\", \"%Y-%m-%d %H:%M:%S\")\n",
    "    y0, m0, d0 = str(date0.year), str(date0.month), str(date0.day)\n",
    "    y1, m1, d1 = str(date1.year), str(date1.month), str(date1.day)\n",
    "    query_word = quote(query_word)\n",
    "    bt = str(int(time.mktime(date0.timetuple())))\n",
    "    et = str(int(time.mktime(date1.timetuple())))\n",
    "    url = 'http://news.baidu.com/ns?from=news&cl=2&bt='+ bt + '&y0='+ y0 +'&m0=' + m0 + '&d0=' + d0 + '&y1=' + y1 + '&m1=' + m1 + '&d1=' + d1 + '&et=' + et + '&q1=' + query_word + '&submit=%B0%D9%B6%C8%D2%BB%CF%C2&q3=&q4=&mt=0&lm=&s=2&begin_date=' + begin_date + '&end_date=' + end_date + '&tn=newsdy&ct1=1&ct=1&rn=20&q6='\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://news.baidu.com/ns?from=news&cl=2&bt=1483286400&y0=2017&m0=1&d0=2&y1=2017&m1=1&d1=3&et=1483459199&q1=%E5%86%9B%E6%B0%91&submit=%B0%D9%B6%C8%D2%BB%CF%C2&q3=&q4=&mt=0&lm=&s=2&begin_date=2017-1-2&end_date=2017-1-3&tn=newsdy&ct1=1&ct=1&rn=20&q6=\n"
     ]
    }
   ],
   "source": [
    "print date_filter('2017-1-2','2017-1-3', '军民')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def page_filter(url, page=0):# append url with pn and rn params\n",
    "    # rn are set to be 20\n",
    "    if page is None:\n",
    "        page = 0\n",
    "    rn = 20\n",
    "    pn = page * rn\n",
    "    rn = str(rn)\n",
    "    pn = str(pn)\n",
    "    url = url + '&pn=' + pn\n",
    "    url = url + '&rn=' + rn\n",
    "    return url\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_with_page(query_word, page=0):\n",
    "    url = search(query_word)\n",
    "    url = page_filter(url, page)\n",
    "    return url\n",
    "\n",
    "def date_filter_with_page(begin_date, end_date, query_word, page=0):\n",
    "    url = date_filter(begin_date, end_date, query_word)\n",
    "    url = page_filter(url, page)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://news.baidu.com/ns?cl=2&tn=news&word=%E5%86%9B%E6%B0%91%E8%9E%8D%E5%90%88&pn=0&rn=20\n",
      "\n",
      "http://news.baidu.com/ns?from=news&cl=2&bt=1483200000&y0=2017&m0=1&d0=1&y1=2017&m1=1&d1=2&et=1483372799&q1=%E5%86%9B%E6%B0%91%E8%9E%8D%E5%90%88&submit=%B0%D9%B6%C8%D2%BB%CF%C2&q3=&q4=&mt=0&lm=&s=2&begin_date=2017-1-1&end_date=2017-1-2&tn=newsdy&ct1=1&ct=1&pn=40&rn=20\n"
     ]
    }
   ],
   "source": [
    "print search_with_page('军民融合')\n",
    "print \n",
    "print date_filter_with_page('2017-1-1', '2017-1-2', '军民融合', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = search_with_page('军民融合', 3)\n",
    "soup = crawl(test)\n",
    "ans = parse(soup)\n",
    "# print ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
